{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaushalpatil/Development/Question Generation Paper/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kaushalpatil/Development/Question Generation Paper/venv/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# %load questiongenerator.py\n",
    "import en_core_web_sm\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoModelForSequenceClassification,\n",
    ")\n",
    "from typing import Any, List, Mapping, Tuple\n",
    "\n",
    "\n",
    "class QuestionGenerator:\n",
    "    \"\"\"A transformer-based NLP system for generating reading comprehension-style questions from\n",
    "    texts. It can generate full sentence questions, multiple choice questions, or a mix of the\n",
    "    two styles.\n",
    "\n",
    "    To filter out low quality questions, questions are assigned a score and ranked once they have\n",
    "    been generated. Only the top k questions will be returned. This behaviour can be turned off\n",
    "    by setting use_evaluator=False.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        QG_PRETRAINED = \"iarfmoose/t5-base-question-generator\"\n",
    "        self.ANSWER_TOKEN = \"<answer>\"\n",
    "        self.CONTEXT_TOKEN = \"<context>\"\n",
    "        self.SEQ_LENGTH = 512\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.qg_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            QG_PRETRAINED, use_fast=False)\n",
    "        self.qg_model = AutoModelForSeq2SeqLM.from_pretrained(QG_PRETRAINED)\n",
    "        self.qg_model.to(self.device)\n",
    "        self.qg_model.eval()\n",
    "\n",
    "        self.qa_evaluator = QAEvaluator()\n",
    "\n",
    "    def generate(\n",
    "        self,\n",
    "        article: str,\n",
    "        use_evaluator: bool = True,\n",
    "        num_questions: bool = None,\n",
    "        answer_style: str = \"all\"\n",
    "    ) -> List:\n",
    "        \"\"\"Takes an article and generates a set of question and answer pairs. If use_evaluator\n",
    "        is True then QA pairs will be ranked and filtered based on their quality. answer_style\n",
    "        should selected from [\"all\", \"sentences\", \"multiple_choice\"].\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Generating questions...\\n\")\n",
    "\n",
    "        qg_inputs, qg_answers = self.generate_qg_inputs(article, answer_style)\n",
    "        generated_questions = self.generate_questions_from_inputs(qg_inputs)\n",
    "\n",
    "        message = \"{} questions doesn't match {} answers\".format(\n",
    "            len(generated_questions), len(qg_answers)\n",
    "        )\n",
    "        assert len(generated_questions) == len(qg_answers), message\n",
    "\n",
    "        if use_evaluator:\n",
    "            print(\"Evaluating QA pairs...\\n\")\n",
    "            encoded_qa_pairs = self.qa_evaluator.encode_qa_pairs(\n",
    "                generated_questions, qg_answers\n",
    "            )\n",
    "            scores = self.qa_evaluator.get_scores(encoded_qa_pairs)\n",
    "\n",
    "            if num_questions:\n",
    "                qa_list = self._get_ranked_qa_pairs(\n",
    "                    generated_questions, qg_answers, scores, num_questions\n",
    "                )\n",
    "            else:\n",
    "                qa_list = self._get_ranked_qa_pairs(\n",
    "                    generated_questions, qg_answers, scores\n",
    "                )\n",
    "\n",
    "        else:\n",
    "            print(\"Skipping evaluation step.\\n\")\n",
    "            qa_list = self._get_all_qa_pairs(generated_questions, qg_answers)\n",
    "\n",
    "        return qa_list\n",
    "\n",
    "    def generate_qg_inputs(self, text: str, answer_style: str) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Given a text, returns a list of model inputs and a list of corresponding answers.\n",
    "        Model inputs take the form \"answer_token <answer text> context_token <context text>\" where\n",
    "        the answer is a string extracted from the text, and the context is the wider text surrounding\n",
    "        the context.\n",
    "        \"\"\"\n",
    "\n",
    "        VALID_ANSWER_STYLES = [\"all\", \"sentences\", \"multiple_choice\"]\n",
    "\n",
    "        if answer_style not in VALID_ANSWER_STYLES:\n",
    "            raise ValueError(\n",
    "                \"Invalid answer style {}. Please choose from {}\".format(\n",
    "                    answer_style, VALID_ANSWER_STYLES\n",
    "                )\n",
    "            )\n",
    "\n",
    "        inputs = []\n",
    "        answers = []\n",
    "\n",
    "        if answer_style == \"sentences\" or answer_style == \"all\":\n",
    "            segments = self._split_into_segments(text)\n",
    "\n",
    "            for segment in segments:\n",
    "                sentences = self._split_text(segment)\n",
    "                prepped_inputs, prepped_answers = self._prepare_qg_inputs(\n",
    "                    sentences, segment\n",
    "                )\n",
    "                inputs.extend(prepped_inputs)\n",
    "                answers.extend(prepped_answers)\n",
    "\n",
    "        if answer_style == \"multiple_choice\" or answer_style == \"all\":\n",
    "            sentences = self._split_text(text)\n",
    "            prepped_inputs, prepped_answers = self._prepare_qg_inputs_MC(\n",
    "                sentences\n",
    "            )\n",
    "            inputs.extend(prepped_inputs)\n",
    "            answers.extend(prepped_answers)\n",
    "\n",
    "        return inputs, answers\n",
    "\n",
    "    def generate_questions_from_inputs(self, qg_inputs: List) -> List[str]:\n",
    "        \"\"\"Given a list of concatenated answers and contexts, with the form:\n",
    "        \"answer_token <answer text> context_token <context text>\", generates a list of \n",
    "        questions.\n",
    "        \"\"\"\n",
    "        generated_questions = []\n",
    "\n",
    "        for qg_input in qg_inputs:\n",
    "            question = self._generate_question(qg_input)\n",
    "            generated_questions.append(question)\n",
    "\n",
    "        return generated_questions\n",
    "\n",
    "    def _split_text(self, text: str) -> List[str]:\n",
    "        \"\"\"Splits the text into sentences, and attempts to split or truncate long sentences.\"\"\"\n",
    "        MAX_SENTENCE_LEN = 128\n",
    "        sentences = re.findall(\".*?[.!\\?]\", text)\n",
    "        cut_sentences = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            if len(sentence) > MAX_SENTENCE_LEN:\n",
    "                cut_sentences.extend(re.split(\"[,;:)]\", sentence))\n",
    "\n",
    "        # remove useless post-quote sentence fragments\n",
    "        cut_sentences = [s for s in sentences if len(s.split(\" \")) > 5]\n",
    "        sentences = sentences + cut_sentences\n",
    "\n",
    "        return list(set([s.strip(\" \") for s in sentences]))\n",
    "\n",
    "    def _split_into_segments(self, text: str) -> List[str]:\n",
    "        \"\"\"Splits a long text into segments short enough to be input into the transformer network.\n",
    "        Segments are used as context for question generation.\n",
    "        \"\"\"\n",
    "        MAX_TOKENS = 490\n",
    "        paragraphs = text.split(\"\\n\")\n",
    "        tokenized_paragraphs = [\n",
    "            self.qg_tokenizer(p)[\"input_ids\"] for p in paragraphs if len(p) > 0\n",
    "        ]\n",
    "        segments = []\n",
    "\n",
    "        while len(tokenized_paragraphs) > 0:\n",
    "            segment = []\n",
    "\n",
    "            while len(segment) < MAX_TOKENS and len(tokenized_paragraphs) > 0:\n",
    "                paragraph = tokenized_paragraphs.pop(0)\n",
    "                segment.extend(paragraph)\n",
    "            segments.append(segment)\n",
    "\n",
    "        return [self.qg_tokenizer.decode(s, skip_special_tokens=True) for s in segments]\n",
    "\n",
    "    def _prepare_qg_inputs(\n",
    "        self,\n",
    "        sentences: List[str],\n",
    "        text: str\n",
    "    ) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Uses sentences as answers and the text as context. Returns a tuple of (model inputs, answers).\n",
    "        Model inputs are \"answer_token <answer text> context_token <context text>\" \n",
    "        \"\"\"\n",
    "        inputs = []\n",
    "        answers = []\n",
    "\n",
    "        for sentence in sentences:\n",
    "            qg_input = f\"{self.ANSWER_TOKEN} {sentence} {self.CONTEXT_TOKEN} {text}\"\n",
    "            inputs.append(qg_input)\n",
    "            answers.append(sentence)\n",
    "\n",
    "        return inputs, answers\n",
    "\n",
    "    def _prepare_qg_inputs_MC(self, sentences: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Performs NER on the text, and uses extracted entities are candidate answers for multiple-choice\n",
    "        questions. Sentences are used as context, and entities as answers. Returns a tuple of (model inputs, answers). \n",
    "        Model inputs are \"answer_token <answer text> context_token <context text>\"\n",
    "        \"\"\"\n",
    "        spacy_nlp = en_core_web_sm.load()\n",
    "        docs = list(spacy_nlp.pipe(sentences, disable=[\"parser\"]))\n",
    "        inputs_from_text = []\n",
    "        answers_from_text = []\n",
    "\n",
    "        for doc, sentence in zip(docs, sentences):\n",
    "            entities = doc.ents\n",
    "            if entities:\n",
    "\n",
    "                for entity in entities:\n",
    "                    qg_input = f\"{self.ANSWER_TOKEN} {entity} {self.CONTEXT_TOKEN} {sentence}\"\n",
    "                    answers = self._get_MC_answers(entity, docs)\n",
    "                    inputs_from_text.append(qg_input)\n",
    "                    answers_from_text.append(answers)\n",
    "\n",
    "        return inputs_from_text, answers_from_text\n",
    "\n",
    "    def _get_MC_answers(self, correct_answer: Any, docs: Any) -> List[Mapping[str, Any]]:\n",
    "        \"\"\"Finds a set of alternative answers for a multiple-choice question. Will attempt to find\n",
    "        alternatives of the same entity type as correct_answer if possible.\n",
    "        \"\"\"\n",
    "        entities = []\n",
    "\n",
    "        for doc in docs:\n",
    "            entities.extend([{\"text\": e.text, \"label_\": e.label_}\n",
    "                            for e in doc.ents])\n",
    "\n",
    "        # remove duplicate elements\n",
    "        entities_json = [json.dumps(kv) for kv in entities]\n",
    "        pool = set(entities_json)\n",
    "        num_choices = (\n",
    "            min(4, len(pool)) - 1\n",
    "        )  # -1 because we already have the correct answer\n",
    "\n",
    "        # add the correct answer\n",
    "        final_choices = []\n",
    "        correct_label = correct_answer.label_\n",
    "        final_choices.append({\"answer\": correct_answer.text, \"correct\": True})\n",
    "        pool.remove(\n",
    "            json.dumps({\"text\": correct_answer.text, \"label_\": correct_answer.label_})\n",
    "        )\n",
    "\n",
    "        # find answers with the same NER label\n",
    "        matches = [e for e in pool if correct_label in e]\n",
    "\n",
    "        # if we don't have enough then add some other random answers\n",
    "        if len(matches) < num_choices:\n",
    "            choices = matches\n",
    "            pool = pool.difference(set(choices))\n",
    "            choices.extend(random.sample(pool, num_choices - len(choices)))\n",
    "        else:\n",
    "            choices = random.sample(matches, num_choices)\n",
    "\n",
    "        choices = [json.loads(s) for s in choices]\n",
    "\n",
    "        for choice in choices:\n",
    "            final_choices.append({\"answer\": choice[\"text\"], \"correct\": False})\n",
    "\n",
    "        random.shuffle(final_choices)\n",
    "        return final_choices\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _generate_question(self, qg_input: str) -> str:\n",
    "        \"\"\"Takes qg_input which is the concatenated answer and context, and uses it to generate\n",
    "        a question sentence. The generated question is decoded and then returned.\n",
    "        \"\"\"\n",
    "        encoded_input = self._encode_qg_input(qg_input)\n",
    "        output = self.qg_model.generate(input_ids=encoded_input[\"input_ids\"])\n",
    "        question = self.qg_tokenizer.decode(\n",
    "            output[0],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        return question\n",
    "\n",
    "    def _encode_qg_input(self, qg_input: str) -> torch.tensor:\n",
    "        \"\"\"Tokenizes a string and returns a tensor of input ids corresponding to indices of tokens in \n",
    "        the vocab.\n",
    "        \"\"\"\n",
    "        return self.qg_tokenizer(\n",
    "            qg_input,\n",
    "            padding='max_length',\n",
    "            max_length=self.SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(self.device)\n",
    "\n",
    "    def _get_ranked_qa_pairs(\n",
    "        self, generated_questions: List[str], qg_answers: List[str], scores, num_questions: int = 10\n",
    "    ) -> List[Mapping[str, str]]:\n",
    "        \"\"\"Ranks generated questions according to scores, and returns the top num_questions examples.\n",
    "        \"\"\"\n",
    "        if num_questions > len(scores):\n",
    "            num_questions = len(scores)\n",
    "            print((\n",
    "                f\"\\nWas only able to generate {num_questions} questions.\",\n",
    "                \"For more questions, please input a longer text.\")\n",
    "            )\n",
    "\n",
    "        qa_list = []\n",
    "\n",
    "        for i in range(num_questions):\n",
    "            index = scores[i]\n",
    "            qa = {\n",
    "                \"question\": generated_questions[index].split(\"?\")[0] + \"?\",\n",
    "                \"answer\": qg_answers[index]\n",
    "            }\n",
    "            qa_list.append(qa)\n",
    "\n",
    "        return qa_list\n",
    "\n",
    "    def _get_all_qa_pairs(self, generated_questions: List[str], qg_answers: List[str]):\n",
    "        \"\"\"Formats question and answer pairs without ranking or filtering.\"\"\"\n",
    "        qa_list = []\n",
    "\n",
    "        for question, answer in zip(generated_questions, qg_answers):\n",
    "            qa = {\n",
    "                \"question\": question.split(\"?\")[0] + \"?\",\n",
    "                \"answer\": answer\n",
    "            }\n",
    "            qa_list.append(qa)\n",
    "\n",
    "        return qa_list\n",
    "\n",
    "\n",
    "class QAEvaluator:\n",
    "    \"\"\"Wrapper for a transformer model which evaluates the quality of question-answer pairs.\n",
    "    Given a QA pair, the model will generate a score. Scores can be used to rank and filter\n",
    "    QA pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        QAE_PRETRAINED = \"iarfmoose/bert-base-cased-qa-evaluator\"\n",
    "        self.SEQ_LENGTH = 512\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.qae_tokenizer = AutoTokenizer.from_pretrained(QAE_PRETRAINED)\n",
    "        self.qae_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            QAE_PRETRAINED\n",
    "        )\n",
    "        self.qae_model.to(self.device)\n",
    "        self.qae_model.eval()\n",
    "\n",
    "    def encode_qa_pairs(self, questions: List[str], answers: List[str]) -> List[torch.tensor]:\n",
    "        \"\"\"Takes a list of questions and a list of answers and encodes them as a list of tensors.\"\"\"\n",
    "        encoded_pairs = []\n",
    "\n",
    "        for question, answer in zip(questions, answers):\n",
    "            encoded_qa = self._encode_qa(question, answer)\n",
    "            encoded_pairs.append(encoded_qa.to(self.device))\n",
    "\n",
    "        return encoded_pairs\n",
    "\n",
    "    def get_scores(self, encoded_qa_pairs: List[torch.tensor]) -> List[float]:\n",
    "        \"\"\"Generates scores for a list of encoded QA pairs.\"\"\"\n",
    "        scores = {}\n",
    "\n",
    "        for i in range(len(encoded_qa_pairs)):\n",
    "            scores[i] = self._evaluate_qa(encoded_qa_pairs[i])\n",
    "\n",
    "        return [\n",
    "            k for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "        ]\n",
    "\n",
    "    def _encode_qa(self, question: str, answer: str) -> torch.tensor:\n",
    "        \"\"\"Concatenates a question and answer, and then tokenizes them. Returns a tensor of \n",
    "        input ids corresponding to indices in the vocab.\n",
    "        \"\"\"\n",
    "        if type(answer) is list:\n",
    "            for a in answer:\n",
    "                if a[\"correct\"]:\n",
    "                    correct_answer = a[\"answer\"]\n",
    "        else:\n",
    "            correct_answer = answer\n",
    "\n",
    "        return self.qae_tokenizer(\n",
    "            text=question,\n",
    "            text_pair=correct_answer,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.SEQ_LENGTH,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _evaluate_qa(self, encoded_qa_pair: torch.tensor) -> float:\n",
    "        \"\"\"Takes an encoded QA pair and returns a score.\"\"\"\n",
    "        output = self.qae_model(**encoded_qa_pair)\n",
    "        return output[0][0][1]\n",
    "\n",
    "\n",
    "def print_qa(qa_list: List[Mapping[str, str]], show_answers: bool = True) -> None:\n",
    "    \"\"\"Formats and prints a list of generated questions and answers.\"\"\"\n",
    "\n",
    "    for i in range(len(qa_list)):\n",
    "        # wider space for 2 digit q nums\n",
    "        space = \" \" * int(np.where(i < 9, 3, 4))\n",
    "\n",
    "        print(f\"{i + 1}) Q: {qa_list[i]['question']}\")\n",
    "\n",
    "        answer = qa_list[i][\"answer\"]\n",
    "\n",
    "        # print a list of multiple choice answers\n",
    "        if type(answer) is list:\n",
    "\n",
    "            if show_answers:\n",
    "                print(\n",
    "                    f\"{space}A: 1. {answer[0]['answer']} \"\n",
    "                    f\"{np.where(answer[0]['correct'], '(correct)', '')}\"\n",
    "                )\n",
    "                for j in range(1, len(answer)):\n",
    "                    print(\n",
    "                        f\"{space + '   '}{j + 1}. {answer[j]['answer']} \"\n",
    "                        f\"{np.where(answer[j]['correct']==True,'(correct)', '')}\"\n",
    "                    )\n",
    "\n",
    "            else:\n",
    "                print(f\"{space}A: 1. {answer[0]['answer']}\")\n",
    "                for j in range(1, len(answer)):\n",
    "                    print(f\"{space + '   '}{j + 1}. {answer[j]['answer']}\")\n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "        # print full sentence answers\n",
    "        else:\n",
    "            if show_answers:\n",
    "                print(f\"{space}A: {answer}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "qg = QuestionGenerator()\n",
    "\n",
    "text = '''Operating System lies in the category of system software. \n",
    "It basically manages all the resources of the computer. \n",
    "An operating system acts as an interface between the software and different parts of the computer or the computer hardware. \n",
    "The operating system is designed in such a way that it can manage the overall resources and operations of the computer. \n",
    "Operating System is a fully integrated set of specialized programs that handle all the operations of the computer. \n",
    "It controls and monitors the execution of all other programs that reside in the computer, which also includes application programs and other system software of the computer. \n",
    "Examples of Operating Systems are Windows, Linux, Mac OS, etc. \n",
    "An Operating System (OS) is a collection of software that manages computer hardware resources and provides common services for computer programs. \n",
    "The operating system is the most important type of system software in a computer system. \n",
    "The operating system helps in improving the computer software as well as hardware. \n",
    "Without OS, it became very difficult for any application to be user-friendly. \n",
    "The Operating System provides a user with an interface that makes any application attractive and user-friendly. \n",
    "The operating System comes with a large number of device drivers that make OS services reachable to the hardware environment. \n",
    "Each and every application present in the system requires the Operating System. \n",
    "The operating system works as a communication channel between system hardware and system software. \n",
    "The operating system helps an application with the hardware part without knowing about the actual hardware configuration. \n",
    "It is one of the most important parts of the system and hence it is present in every device, whether large or small device. \n",
    "Functions of the Operating System: Resource Management: The operating system manages and allocates memory, CPU time, and other hardware resources among the various programs and processes running on the computer. \n",
    "Process Management: The operating system is responsible for starting, stopping, and managing processes and programs. It also controls the scheduling of processes and allocates resources to them. \n",
    "Memory Management: The operating system manages the computer's primary memory and provides mechanisms for optimizing memory usage. \n",
    "Security: The operating system provides a secure environment for the user, applications, and data by implementing security policies and mechanisms such as access controls and encryption. \n",
    "Job Accounting: It keeps track of time and resources used by various jobs or users. \n",
    "File Management: The operating system is responsible for organizing and managing the file system, including the creation, deletion, and manipulation of files and directories. \n",
    "Device Management: The operating system manages input/output devices such as printers, keyboards, mice, and displays. It provides the necessary drivers and interfaces to enable communication between the devices and the computer. \n",
    "Networking: The operating system provides networking capabilities such as establishing and managing network connections, handling network protocols, and sharing resources such as printers and files over a network. \n",
    "User Interface: The operating system provides a user interface that enables users to interact with the computer system. This can be a Graphical User Interface (GUI), a Command-Line Interface (CLI), or a combination of both. \n",
    "Backup and Recovery: The operating system provides mechanisms for backing up data and recovering it in case of system failures, errors, or disasters. \n",
    "Virtualization: The operating system provides virtualization capabilities that allow multiple operating systems or applications to run on a single physical machine. This can enable efficient use of resources and flexibility in managing workloads. \n",
    "Performance Monitoring: The operating system provides tools for monitoring and optimizing system performance, including identifying bottlenecks, optimizing resource usage, and analyzing system logs and metrics. \n",
    "Time-Sharing: The operating system enables multiple users to share a computer system and its resources simultaneously by providing time-sharing mechanisms that allocate resources fairly and efficiently. \n",
    "System Calls: The operating system provides a set of system calls that enable applications to interact with the operating system and access its resources. System calls provide a standardized interface between applications and the operating system, enabling portability and compatibility across different hardware and software platforms. \n",
    "Error-detecting Aids: These contain methods that include the production of dumps, traces, error messages, and other debugging and error-detecting methods.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating questions...\n",
      "\n",
      "Evaluating QA pairs...\n",
      "\n",
      "1) Q: What is the most common operating system?\n",
      "   A: 1. Linux \n",
      "      2. the Operating System \n",
      "      3. Windows (correct)\n",
      "      4. Graphical User Interface \n",
      "\n",
      "2) Q: What is the device management?\n",
      "   A: 1. Process Management \n",
      "      2. Device Management (correct)\n",
      "      3. CPU \n",
      "      4. CLI \n",
      "\n",
      "3) Q: What is the most common operating system?\n",
      "   A: 1. Graphical User Interface \n",
      "      2. The Operating System \n",
      "      3. Device Management \n",
      "      4. Mac OS (correct)\n",
      "\n",
      "4) Q: What is the primary memory of the computer?\n",
      "   A: 1. Memory Management (correct)\n",
      "      2. CPU \n",
      "      3. The Operating System \n",
      "      4. the Operating System \n",
      "\n",
      "5) Q: What is the function of the operating system?\n",
      "   A: 1. the Operating System \n",
      "      2. CPU (correct)\n",
      "      3. GUI \n",
      "      4. The Operating System \n",
      "\n",
      "6) Q: What is a GUI?\n",
      "   A: 1. Graphical User Interface (correct)\n",
      "      2. GUI \n",
      "      3. the Operating System \n",
      "      4. Windows \n",
      "\n",
      "7) Q: What is the role of the operating system in process management?\n",
      "   A: 1. Process Management (correct)\n",
      "      2. the Operating System \n",
      "      3. Command-Line Interface \n",
      "      4. GUI \n",
      "\n",
      "8) Q: What can be a GUI?\n",
      "   A: 1. The Operating System \n",
      "      2. Device Management \n",
      "      3. CPU \n",
      "      4. Command-Line Interface (correct)\n",
      "\n",
      "9) Q: Can be a GUI, a Command Line Interface (CLI), or a combination?\n",
      "   A: 1. GUI (correct)\n",
      "      2. Device Management \n",
      "      3. Memory Management \n",
      "      4. CLI \n",
      "\n",
      "10) Q: What is the operating system?\n",
      "    A: 1. Device Management \n",
      "       2. the Operating System \n",
      "       3. The Operating System (correct)\n",
      "       4. CLI \n",
      "\n"
     ]
    }
   ],
   "source": [
    "qa_list = qg.generate(\n",
    "    text, \n",
    "    num_questions=10, \n",
    "    answer_style='multiple_choice'\n",
    ")\n",
    "print_qa(qa_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('result-2-t5-base-qg.json', 'w') as fp:\n",
    "    json.dump(qa_list, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
